{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe7b85df-2842-4e7f-bb5f-039714497aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the folder containing the dataset\n",
    "dataset_folder = \"keypoints\"\n",
    "\n",
    "# Define the label map\n",
    "label_map = {'frez': 0, 'hurry': 1, 'listen': 2, 'stop': 3, 'hostage': 4, 'understand': 5, 'pistol': 6, 'come': 7}  # Add more labels as needed\n",
    "\n",
    "# Initialize arrays\n",
    "labels = []\n",
    "data = []\n",
    "\n",
    "# Function to check for NaNs in a DataFrame\n",
    "def contains_nan(df):\n",
    "    return df.isnull().values.any()\n",
    "\n",
    "# Iterate through each folder in the dataset directory\n",
    "for folder_name in os.listdir(dataset_folder):\n",
    "    folder_path = os.path.join(dataset_folder, folder_name)\n",
    "    \n",
    "    # Check if it's a directory\n",
    "    if os.path.isdir(folder_path):\n",
    "        # Extract label from folder name using label_map\n",
    "        label = label_map.get(folder_name, None)\n",
    "        if label is None:\n",
    "            continue\n",
    "        \n",
    "        # Iterate through each CSV file in the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            # Read CSV file\n",
    "            df = pd.read_csv(file_path)\n",
    "            # Check for NaNs\n",
    "            if contains_nan(df):\n",
    "                print(f'NaN values found in file: {file_path}')\n",
    "            # Flatten the data and append to the data array\n",
    "            file_data = df.values\n",
    "            # Append the file data to the list\n",
    "            data.append(file_data)\n",
    "            labels.append(label)  # Append the label\n",
    "\n",
    "# Convert data and labels to numpy arrays for further processing if needed\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98d9941-a22a-4d04-91d3-42f9a070da65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the root directory containing the folders and CSV files\n",
    "# root_directory = 'keypoints'\n",
    "\n",
    "# # List of columns to be deleted\n",
    "# columns_to_delete = ['class_label', 'pose_keypoint_1_x', 'pose_keypoint_1_y', 'pose_keypoint_1_z', 'pose_keypoint_3_x', 'pose_keypoint_3_y', 'pose_keypoint_3_z', 'pose_keypoint_4_x', 'pose_keypoint_4_y', 'pose_keypoint_4_z', 'pose_keypoint_6_x', 'pose_keypoint_6_y', 'pose_keypoint_6_z', 'pose_keypoint_14_x', 'pose_keypoint_14_y', 'pose_keypoint_14_z', 'pose_keypoint_16_x', 'pose_keypoint_16_y', 'pose_keypoint_16_z', 'pose_keypoint_18_x', 'pose_keypoint_18_y', 'pose_keypoint_18_z', 'pose_keypoint_20_x', 'pose_keypoint_20_y', 'pose_keypoint_20_z', 'pose_keypoint_22_x', 'pose_keypoint_22_y', 'pose_keypoint_22_z', 'pose_keypoint_25_x', 'pose_keypoint_25_y', 'pose_keypoint_25_z', 'pose_keypoint_26_x', 'pose_keypoint_26_y', 'pose_keypoint_26_z', 'pose_keypoint_27_x', 'pose_keypoint_27_y', 'pose_keypoint_27_z', 'pose_keypoint_28_x', 'pose_keypoint_28_y', 'pose_keypoint_28_z', 'pose_keypoint_29_x', 'pose_keypoint_29_y', 'pose_keypoint_29_z', 'pose_keypoint_30_x', 'pose_keypoint_30_y', 'pose_keypoint_30_z', 'pose_keypoint_31_x', 'pose_keypoint_31_y', 'pose_keypoint_31_z', 'pose_keypoint_32_x', 'pose_keypoint_32_y', 'pose_keypoint_32_z']  # Replace with your column names\n",
    "\n",
    "# # Function to delete specified columns from a DataFrame\n",
    "# def delete_columns(df, columns):\n",
    "#     return df.drop(columns=columns, errors='ignore')\n",
    "\n",
    "# # Function to process CSV files in the directory and subdirectories\n",
    "# def process_csv_files(directory, columns_to_delete):\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             if filename.endswith('.csv'):\n",
    "#                 file_path = os.path.join(foldername, filename)\n",
    "#                 try:\n",
    "#                     df = pd.read_csv(file_path)\n",
    "#                     # Delete the specified columns\n",
    "#                     df = delete_columns(df, columns_to_delete)\n",
    "#                     # Save the modified DataFrame back to CSV\n",
    "#                     df.to_csv(file_path, index=False)\n",
    "#                     print(f'Processed file: {file_path}')\n",
    "#                 except Exception as e:\n",
    "#                     print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "# # Run the function\n",
    "# process_csv_files(root_directory, columns_to_delete)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb0b2c8-3645-4b21-88c9-4fbdb49cf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import pandas as pd\n",
    "\n",
    "# # Define the root directory containing the folders and CSV files\n",
    "# root_directory = 'keypoints'\n",
    "\n",
    "# # Function to check for null values in a DataFrame\n",
    "# def contains_nan(df):\n",
    "#     return df.isnull().values.any()\n",
    "\n",
    "# # Function to find CSV files with null values\n",
    "# def find_null_in_csv_files(directory):\n",
    "#     for foldername, subfolders, filenames in os.walk(directory):\n",
    "#         for filename in filenames:\n",
    "#             if filename.endswith('.csv'):\n",
    "#                 file_path = os.path.join(foldername, filename)\n",
    "#                 try:\n",
    "#                     df = pd.read_csv(file_path)\n",
    "#                     if contains_nan(df):\n",
    "#                         print(f'NaN values found in file: {file_path}')\n",
    "#                 except Exception as e:\n",
    "#                     print(f'Error processing file {file_path}: {e}')\n",
    "\n",
    "# # Run the function\n",
    "# find_null_in_csv_files(root_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46ec226-073c-4268-bdba-f6cbbdb4db0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Define the path to the CSV file\n",
    "# file_path = 'keypoints\\\\hurry\\\\4.csv'\n",
    "\n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv(file_path)\n",
    "\n",
    "# # Check for null values in each row\n",
    "# null_rows = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# # Print the indices and the rows with null values\n",
    "# for index, row in null_rows.iterrows():\n",
    "#     print(f'Null value found in row {index + 1}:')\n",
    "#     print(row)\n",
    "#     print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77485d6d-487d-41cf-af67-ffad3073bc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Convert data and labels to numpy arrays\n",
    "X = np.array(data)\n",
    "y = to_categorical(labels).astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "421314ea-21ea-4bc1-bd4d-98d5e0550b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in X_train: 0\n",
      "NaNs in y_train: 0\n",
      "Infs in X_train: 0\n",
      "Infs in y_train: 0\n",
      "NaNs in X_test: 0\n",
      "NaNs in y_test: 0\n",
      "Infs in X_test: 0\n",
      "Infs in y_test: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure there are no NaNs or infinite values in the input data and labels\n",
    "print(f'NaNs in X_train: {np.isnan(X_train).sum()}')\n",
    "print(f'NaNs in y_train: {np.isnan(y_train).sum()}')\n",
    "print(f'Infs in X_train: {np.isinf(X_train).sum()}')\n",
    "print(f'Infs in y_train: {np.isinf(y_train).sum()}')\n",
    "\n",
    "print(f'NaNs in X_test: {np.isnan(X_test).sum()}')\n",
    "print(f'NaNs in y_test: {np.isnan(y_test).sum()}')\n",
    "print(f'Infs in X_test: {np.isinf(X_test).sum()}')\n",
    "print(f'Infs in y_test: {np.isinf(y_test).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6747c0-fdbe-449b-98df-a94d255c9931",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6caa21aa-9474-432a-98ea-0488d9a226db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117a9b3d-d798-4791-af0a-1c13eb9b9475",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181a0cb-226b-4039-b066-6313aa2ceed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fe29c8-9463-42c4-a1c4-2b4fa80b48a2",
   "metadata": {},
   "source": [
    "# implimented using ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980eb1b0-762c-42fe-b94c-3aca0380be08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "8/8 [==============================] - 1s 18ms/step - loss: 2.4910 - categorical_accuracy: 0.1719\n",
      "Epoch 2/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.7957 - categorical_accuracy: 0.3594\n",
      "Epoch 3/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.5659 - categorical_accuracy: 0.3711\n",
      "Epoch 4/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.2841 - categorical_accuracy: 0.5273\n",
      "Epoch 5/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 1.0430 - categorical_accuracy: 0.6992\n",
      "Epoch 6/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.8713 - categorical_accuracy: 0.7891\n",
      "Epoch 7/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.7371 - categorical_accuracy: 0.9180\n",
      "Epoch 8/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6291 - categorical_accuracy: 0.8984\n",
      "Epoch 9/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.5229 - categorical_accuracy: 0.9023\n",
      "Epoch 10/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.4499 - categorical_accuracy: 0.9648\n",
      "Epoch 11/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3974 - categorical_accuracy: 0.9375\n",
      "Epoch 12/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3271 - categorical_accuracy: 0.9805\n",
      "Epoch 13/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.2877 - categorical_accuracy: 0.9609\n",
      "Epoch 14/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.3111 - categorical_accuracy: 0.9492\n",
      "Epoch 15/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.2174 - categorical_accuracy: 0.9648\n",
      "Epoch 16/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1924 - categorical_accuracy: 0.9922\n",
      "Epoch 17/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1659 - categorical_accuracy: 0.9961\n",
      "Epoch 18/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1423 - categorical_accuracy: 0.9961\n",
      "Epoch 19/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.1331 - categorical_accuracy: 1.0000\n",
      "Epoch 20/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1149 - categorical_accuracy: 0.9922\n",
      "Epoch 21/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.1022 - categorical_accuracy: 1.0000\n",
      "Epoch 22/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0963 - categorical_accuracy: 1.0000\n",
      "Epoch 23/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0887 - categorical_accuracy: 0.9961\n",
      "Epoch 24/500\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0783 - categorical_accuracy: 1.0000\n",
      "Epoch 25/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0720 - categorical_accuracy: 1.0000\n",
      "Epoch 26/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0666 - categorical_accuracy: 1.0000\n",
      "Epoch 27/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0630 - categorical_accuracy: 1.0000\n",
      "Epoch 28/500\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0585 - categorical_accuracy: 1.0000\n",
      "Epoch 29/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0546 - categorical_accuracy: 1.0000\n",
      "Epoch 30/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0527 - categorical_accuracy: 0.9961\n",
      "Epoch 31/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0448 - categorical_accuracy: 1.0000\n",
      "Epoch 32/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0427 - categorical_accuracy: 1.0000\n",
      "Epoch 33/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0426 - categorical_accuracy: 1.0000\n",
      "Epoch 34/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0402 - categorical_accuracy: 1.0000\n",
      "Epoch 35/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0356 - categorical_accuracy: 1.0000\n",
      "Epoch 36/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0330 - categorical_accuracy: 1.0000\n",
      "Epoch 37/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0309 - categorical_accuracy: 1.0000\n",
      "Epoch 38/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0286 - categorical_accuracy: 1.0000\n",
      "Epoch 39/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0274 - categorical_accuracy: 1.0000\n",
      "Epoch 40/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0271 - categorical_accuracy: 1.0000\n",
      "Epoch 41/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0258 - categorical_accuracy: 1.0000\n",
      "Epoch 42/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0226 - categorical_accuracy: 1.0000\n",
      "Epoch 43/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0219 - categorical_accuracy: 1.0000\n",
      "Epoch 44/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0209 - categorical_accuracy: 1.0000\n",
      "Epoch 45/500\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0197 - categorical_accuracy: 1.0000\n",
      "Epoch 46/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0189 - categorical_accuracy: 1.0000\n",
      "Epoch 47/500\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0183 - categorical_accuracy: 1.0000\n",
      "Epoch 48/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0175 - categorical_accuracy: 1.0000\n",
      "Epoch 49/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0167 - categorical_accuracy: 1.0000\n",
      "Epoch 50/500\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0166 - categorical_accuracy: 1.0000\n",
      "Epoch 51/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0168 - categorical_accuracy: 1.0000\n",
      "Epoch 52/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0148 - categorical_accuracy: 1.0000\n",
      "Epoch 53/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0144 - categorical_accuracy: 1.0000\n",
      "Epoch 54/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0144 - categorical_accuracy: 1.0000\n",
      "Epoch 55/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0140 - categorical_accuracy: 1.0000\n",
      "Epoch 56/500\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0137 - categorical_accuracy: 1.0000\n",
      "Epoch 57/500\n",
      "4/8 [==============>...............] - ETA: 0s - loss: 0.0140 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 25>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Step 5: Train the model\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_flattened\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m ):\n\u001b[0;32m   1782\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1783\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1785\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    864\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    865\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    866\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 867\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    872\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    873\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1266\u001b[0m     args,\n\u001b[0;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1268\u001b[0m     executing_eagerly)\n\u001b[0;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    216\u001b[0m   \u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    262\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1494\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "\n",
    "\n",
    "log_dir = os.path.join(\"logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "num_samples, dim1, dim2 = X_train.shape\n",
    "X_train_flattened = X_train.reshape(num_samples, dim1 * dim2)\n",
    "\n",
    "\n",
    "# Step 3: Define the ANN model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=dim1 * dim2, activation='relu'))   \n",
    "model.add(Dense(64, activation='relu'))  \n",
    "model.add(Dense(8, activation='softmax'))              \n",
    "\n",
    "# Step 4: Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Step 5: Train the model\n",
    "model.fit(X_train_flattened, y_train, epochs=500, batch_size=32,callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce7219c-73cc-4d16-91a2-ba7586d909e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Make predictions on the test set\n",
    "num_samples, dim1, dim2 = X_test.shape\n",
    "X_test_flattened = X_test.reshape(num_samples, dim1 * dim2)\n",
    "y_pred_prob = model.predict(X_test_flattened)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test if one-hot encoded\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "#accuracy and loss\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:')\n",
    "print(accuracy)\n",
    "# Generate the confusion matrix\n",
    "print('confusion matrix:')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be10282-2d6b-44ab-8816-34cd3c97e645",
   "metadata": {},
   "source": [
    "# Implimented using RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb51d052-3258-48e8-b6d9-e83291b3a893",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 3s 28ms/step - loss: 2.1264 - categorical_accuracy: 0.1641\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.9840 - categorical_accuracy: 0.2070\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.8558 - categorical_accuracy: 0.4102\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.6146 - categorical_accuracy: 0.4531\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3950 - categorical_accuracy: 0.4688\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 1.1232 - categorical_accuracy: 0.5703\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.8720 - categorical_accuracy: 0.6875\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7896 - categorical_accuracy: 0.6758\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5969 - categorical_accuracy: 0.7812\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5594 - categorical_accuracy: 0.7656\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5974 - categorical_accuracy: 0.7383\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5621 - categorical_accuracy: 0.7773\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.5152 - categorical_accuracy: 0.7930\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.7254 - categorical_accuracy: 0.7148\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6448 - categorical_accuracy: 0.7578\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.6013 - categorical_accuracy: 0.7578\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.5519 - categorical_accuracy: 0.7930\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4732 - categorical_accuracy: 0.8281\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3064 - categorical_accuracy: 0.9219\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.2787 - categorical_accuracy: 0.8945\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2047 - categorical_accuracy: 0.9375\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2019 - categorical_accuracy: 0.9414\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1994 - categorical_accuracy: 0.9297\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2355 - categorical_accuracy: 0.9102\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.3128 - categorical_accuracy: 0.8867\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.1798 - categorical_accuracy: 0.9492\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2276 - categorical_accuracy: 0.9258\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1456 - categorical_accuracy: 0.9453\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2395 - categorical_accuracy: 0.9180\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.2272 - categorical_accuracy: 0.9141\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2285 - categorical_accuracy: 0.9219\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.4069 - categorical_accuracy: 0.8398\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.3801 - categorical_accuracy: 0.8789\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.2746 - categorical_accuracy: 0.9102\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1763 - categorical_accuracy: 0.9492\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.1005 - categorical_accuracy: 0.9844\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0617 - categorical_accuracy: 0.9922\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0709 - categorical_accuracy: 0.9805\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0355 - categorical_accuracy: 0.9883\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0536 - categorical_accuracy: 0.9844\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0904 - categorical_accuracy: 0.9688\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.1060 - categorical_accuracy: 0.9648\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0273 - categorical_accuracy: 0.9961\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0442 - categorical_accuracy: 0.9844\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0171 - categorical_accuracy: 1.0000\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0359 - categorical_accuracy: 0.9922\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0494 - categorical_accuracy: 0.9844\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0224 - categorical_accuracy: 0.9922\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0134 - categorical_accuracy: 0.9961\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0067 - categorical_accuracy: 1.0000\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0062 - categorical_accuracy: 1.0000\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0045 - categorical_accuracy: 1.0000\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0027 - categorical_accuracy: 1.0000\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0019 - categorical_accuracy: 1.0000\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0013 - categorical_accuracy: 1.0000\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 0.0011 - categorical_accuracy: 1.0000\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.7891e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.1079e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 7.1825e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 6.5176e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 6.0503e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 5.5908e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 5.2148e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 4.8821e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 4.5755e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 4.3099e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 4.0756e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.8569e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 3.6524e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.4638e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.3040e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.1477e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 3.0082e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.8753e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.7547e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 2.6447e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.5451e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 2.4361e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.3385e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.2466e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.1682e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.0865e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 2.0124e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.9425e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.8798e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.8214e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.7575e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.7090e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.6500e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.5978e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5489e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.5000e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 1.4585e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.4117e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3715e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.3312e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.2941e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.2559e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 53ms/step - loss: 1.2217e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 30ms/step - loss: 1.1854e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 1.1542e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.1204e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 1.0892e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 36ms/step - loss: 1.0591e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0307e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 1.0063e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 9.7780e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 9.5219e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 32ms/step - loss: 9.3149e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 9.1081e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.8446e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.6381e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 63ms/step - loss: 8.4383e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 8.2448e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 8.0612e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 7.8680e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 7.6954e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 7.5345e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 7.3875e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 7.2128e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 7.0663e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 6.9154e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 6.7734e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 6.6390e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 6.5012e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 6.3703e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 6.2522e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 6.1168e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 6.0053e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 5.8941e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 0s 27ms/step - loss: 5.7833e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 5.6808e-05 - categorical_accuracy: 1.0000\n",
      "Epoch 133/1000\n",
      "7/8 [=========================>....] - ETA: 0s - loss: 5.4088e-05 - categorical_accuracy: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtb_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\training.py:1774\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1772\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1774\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1775\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1776\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1777\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1780\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1781\u001b[0m         ):\n\u001b[0;32m   1782\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:687\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    685\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    686\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 687\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    689\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:817\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    814\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_variable_op()\n\u001b[0;32m    815\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    816\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[1;32m--> 817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marray_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1260\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1258\u001b[0m \u001b[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1260\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m dispatch_target(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[0;32m   1262\u001b[0m   \u001b[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[0;32m   1263\u001b[0m   \u001b[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[0;32m   1264\u001b[0m   result \u001b[38;5;241m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:321\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraph\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    318\u001b[0m   \u001b[38;5;66;03m# Make sure we get an input with handle data attached from resource\u001b[39;00m\n\u001b[0;32m    319\u001b[0m   \u001b[38;5;66;03m# variables. Variables have correct handle data when graph building.\u001b[39;00m\n\u001b[0;32m    320\u001b[0m   \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m--> 321\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43midentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;66;03m# Propagate handle data for happier shape inference for resource variables.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_handle_data\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py:4975\u001b[0m, in \u001b[0;36midentity\u001b[1;34m(input, name)\u001b[0m\n\u001b[0;32m   4973\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   4974\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4975\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4976\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIdentity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4977\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   4978\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import os\n",
    "\n",
    "# Define log directory for TensorBoard\n",
    "log_dir = os.path.join(\"logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(128, activation='relu', return_sequences=True, input_shape=(70, 111)))\n",
    "model.add(SimpleRNN(64, activation='relu', return_sequences=True))\n",
    "model.add(SimpleRNN(64, activation='relu', return_sequences=False))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train, epochs=1000, callbacks=[tb_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bac54ba9-a0d1-4cfe-9e00-5711e6cde41c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 11ms/step\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         9\n",
      "           2       1.00      1.00      1.00        11\n",
      "           3       1.00      1.00      1.00         8\n",
      "           4       1.00      1.00      1.00         5\n",
      "           5       1.00      1.00      1.00         8\n",
      "           6       1.00      1.00      1.00         9\n",
      "           7       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n",
      "confusion matrix:\n",
      "[[ 4  0  0  0  0  0  0  0]\n",
      " [ 0  9  0  0  0  0  0  0]\n",
      " [ 0  0 11  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  5  0  0  0]\n",
      " [ 0  0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0  0  0  9  0]\n",
      " [ 0  0  0  0  0  0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test if one-hot encoded\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "#accuracy and loss\n",
    "accuracy = classification_report(y_test, y_pred)\n",
    "print('classification report:')\n",
    "print(accuracy)\n",
    "# Generate the confusion matrix\n",
    "print('confusion matrix:')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f3accd1-c94e-40dd-844a-9a09ed95ff28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " simple_rnn (SimpleRNN)      (None, 70, 128)           30720     \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 70, 64)            12352     \n",
      "                                                                 \n",
      " simple_rnn_2 (SimpleRNN)    (None, 64)                8256      \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 53672 (209.66 KB)\n",
      "Trainable params: 53672 (209.66 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c926dd-efa4-47d9-a1d1-40573cb9ca27",
   "metadata": {},
   "source": [
    "# Implimented using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210b3a41-b60f-4c1f-bd53-440908bcf69c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard \n",
    "\n",
    "\n",
    "log_dir = os.path.join(\"logs\")\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(70, 111))) \n",
    "model.add(LSTM(128, activation='relu', return_sequences=True)) \n",
    "model.add(LSTM(64, activation='relu', return_sequences=False)) \n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=1000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcec2ab-e6e2-4e47-b585-6be36657e6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f7ac427-6145-4b8a-a6c1-b006b4f5ee32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 4s 96ms/step - loss: 2.1500 - categorical_accuracy: 0.1211\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.0423 - categorical_accuracy: 0.2109\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.0556 - categorical_accuracy: 0.1484\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.9656 - categorical_accuracy: 0.1875\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.8954 - categorical_accuracy: 0.2539\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.1007 - categorical_accuracy: 0.1641\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 4.8173 - categorical_accuracy: 0.0742\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 2.0602 - categorical_accuracy: 0.1602\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.0317 - categorical_accuracy: 0.2266\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 3.5246 - categorical_accuracy: 0.2344\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.0715 - categorical_accuracy: 0.2227\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0716 - categorical_accuracy: 0.2617\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.0667 - categorical_accuracy: 0.2344\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 1s 91ms/step - loss: 2.0600 - categorical_accuracy: 0.1875\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0128 - categorical_accuracy: 0.2578\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.0401 - categorical_accuracy: 0.2930\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0278 - categorical_accuracy: 0.2930\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0027 - categorical_accuracy: 0.3203\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.9352 - categorical_accuracy: 0.2656\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.9842 - categorical_accuracy: 0.1992\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.9403 - categorical_accuracy: 0.2422\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.9787 - categorical_accuracy: 0.2461\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.0594 - categorical_accuracy: 0.1250\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 2.0589 - categorical_accuracy: 0.1289\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 2.0484 - categorical_accuracy: 0.1914\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0325 - categorical_accuracy: 0.2109\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.0068 - categorical_accuracy: 0.1602\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 1.9926 - categorical_accuracy: 0.2266\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.0279 - categorical_accuracy: 0.2266\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 1s 92ms/step - loss: 2.0037 - categorical_accuracy: 0.2656\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 1.9647 - categorical_accuracy: 0.2656\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.8747 - categorical_accuracy: 0.3633\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 8.2117 - categorical_accuracy: 0.1797\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 2.0635 - categorical_accuracy: 0.1523\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 1.9609 - categorical_accuracy: 0.1562\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 1s 99ms/step - loss: 2.0011 - categorical_accuracy: 0.2188\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 1s 100ms/step - loss: 1.9061 - categorical_accuracy: 0.2188\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 1.7337 - categorical_accuracy: 0.2227\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.8174 - categorical_accuracy: 0.2500\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 1.8698 - categorical_accuracy: 0.2852\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.7128 - categorical_accuracy: 0.2969\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.6164 - categorical_accuracy: 0.2930\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 13.7631 - categorical_accuracy: 0.2227\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 2.3631 - categorical_accuracy: 0.1328\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 965.6152 - categorical_accuracy: 0.1680\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 1s 94ms/step - loss: 2.0652 - categorical_accuracy: 0.1289\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.8576 - categorical_accuracy: 0.1602\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 1s 93ms/step - loss: 2.3030 - categorical_accuracy: 0.1250\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 2.5207 - categorical_accuracy: 0.1328\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 2.1170 - categorical_accuracy: 0.1406\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 2.0513 - categorical_accuracy: 0.1641\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 2.1329 - categorical_accuracy: 0.1641\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.0391 - categorical_accuracy: 0.1914\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.9978 - categorical_accuracy: 0.1875\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.9895 - categorical_accuracy: 0.1992\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 1.8687 - categorical_accuracy: 0.2461\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.7661 - categorical_accuracy: 0.3164\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 1.7100 - categorical_accuracy: 0.3281\n",
      "Epoch 59/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.8071 - categorical_accuracy: 0.2539\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 1.7513 - categorical_accuracy: 0.2695\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.7357 - categorical_accuracy: 0.3047\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 2.4867 - categorical_accuracy: 0.1836\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 2.1207 - categorical_accuracy: 0.1250\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 2.1466 - categorical_accuracy: 0.1680\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 2.0499 - categorical_accuracy: 0.2500\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 1s 96ms/step - loss: 1.9494 - categorical_accuracy: 0.2578\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.7596 - categorical_accuracy: 0.3086\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 1s 104ms/step - loss: 1.6776 - categorical_accuracy: 0.3398\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.5931 - categorical_accuracy: 0.3906\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 1.4771 - categorical_accuracy: 0.3789\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 1s 98ms/step - loss: 1.3802 - categorical_accuracy: 0.4609\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 1s 103ms/step - loss: 2.1178 - categorical_accuracy: 0.2031\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 1.8872 - categorical_accuracy: 0.1992\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 1.8288 - categorical_accuracy: 0.2344\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.9257 - categorical_accuracy: 0.1914\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.8852 - categorical_accuracy: 0.1914\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.8593 - categorical_accuracy: 0.2148\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.7710 - categorical_accuracy: 0.2539\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 1.7149 - categorical_accuracy: 0.3047\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.6919 - categorical_accuracy: 0.3320\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.8100 - categorical_accuracy: 0.2422\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 1s 107ms/step - loss: 1.6611 - categorical_accuracy: 0.3242\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 1s 110ms/step - loss: 1.4819 - categorical_accuracy: 0.3867\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 1.3913 - categorical_accuracy: 0.4414\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.3304 - categorical_accuracy: 0.4297\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 1s 97ms/step - loss: 1.2225 - categorical_accuracy: 0.5469\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.1559 - categorical_accuracy: 0.6016\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 1s 108ms/step - loss: 1.1149 - categorical_accuracy: 0.5391\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 1s 106ms/step - loss: 0.9827 - categorical_accuracy: 0.5859\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 4.9061 - categorical_accuracy: 0.1953\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 2.3406 - categorical_accuracy: 0.1367\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 2.1588 - categorical_accuracy: 0.1250\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 2.0900 - categorical_accuracy: 0.1484\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 2.0609 - categorical_accuracy: 0.1719\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 2.0173 - categorical_accuracy: 0.1797\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.9439 - categorical_accuracy: 0.2734\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 1s 105ms/step - loss: 1.7508 - categorical_accuracy: 0.3750\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.6355 - categorical_accuracy: 0.4258\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 1s 102ms/step - loss: 1.4773 - categorical_accuracy: 0.4414\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 1.3744 - categorical_accuracy: 0.4727\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 1.2871 - categorical_accuracy: 0.5352\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 1.1389 - categorical_accuracy: 0.5742\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 1.2925 - categorical_accuracy: 0.4961\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 1.7185 - categorical_accuracy: 0.3633\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 1.6161 - categorical_accuracy: 0.3906\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 1.3972 - categorical_accuracy: 0.4688\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 1.2993 - categorical_accuracy: 0.5039\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 1.2018 - categorical_accuracy: 0.5273\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 1.0859 - categorical_accuracy: 0.5703\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 1.0232 - categorical_accuracy: 0.6055\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.9889 - categorical_accuracy: 0.6562\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.8771 - categorical_accuracy: 0.7148\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.9549 - categorical_accuracy: 0.5898\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.9364 - categorical_accuracy: 0.6758\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 1s 109ms/step - loss: 0.8688 - categorical_accuracy: 0.6641\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.8682 - categorical_accuracy: 0.6875\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.8172 - categorical_accuracy: 0.6719\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.8748 - categorical_accuracy: 0.6914\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 1s 158ms/step - loss: 0.8528 - categorical_accuracy: 0.6914\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.7891 - categorical_accuracy: 0.7148\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 1s 156ms/step - loss: 0.8168 - categorical_accuracy: 0.6992\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 1.1724 - categorical_accuracy: 0.6016\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 1.2393 - categorical_accuracy: 0.5234\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.9690 - categorical_accuracy: 0.6484\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.8316 - categorical_accuracy: 0.7148\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.7507 - categorical_accuracy: 0.7227\n",
      "Epoch 127/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.7317 - categorical_accuracy: 0.7539\n",
      "Epoch 128/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.6889 - categorical_accuracy: 0.7461\n",
      "Epoch 129/1000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.6517 - categorical_accuracy: 0.7461\n",
      "Epoch 130/1000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 0.6064 - categorical_accuracy: 0.7578\n",
      "Epoch 131/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.5564 - categorical_accuracy: 0.7461\n",
      "Epoch 132/1000\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.5805 - categorical_accuracy: 0.7656\n",
      "Epoch 133/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.5322 - categorical_accuracy: 0.7773\n",
      "Epoch 134/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.6256 - categorical_accuracy: 0.7266\n",
      "Epoch 135/1000\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.6083 - categorical_accuracy: 0.7656\n",
      "Epoch 136/1000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.5770 - categorical_accuracy: 0.7383\n",
      "Epoch 137/1000\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 0.5261 - categorical_accuracy: 0.7930\n",
      "Epoch 138/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.5176 - categorical_accuracy: 0.7812\n",
      "Epoch 139/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.4321 - categorical_accuracy: 0.8555\n",
      "Epoch 140/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.0999 - categorical_accuracy: 0.5977\n",
      "Epoch 141/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 1.2722 - categorical_accuracy: 0.4648\n",
      "Epoch 142/1000\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 1.2419 - categorical_accuracy: 0.4688\n",
      "Epoch 143/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 1.2781 - categorical_accuracy: 0.4727\n",
      "Epoch 144/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 1.1164 - categorical_accuracy: 0.5586\n",
      "Epoch 145/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 1.0112 - categorical_accuracy: 0.5781\n",
      "Epoch 146/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.9321 - categorical_accuracy: 0.6172\n",
      "Epoch 147/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 1.0957 - categorical_accuracy: 0.5469\n",
      "Epoch 148/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 1.0690 - categorical_accuracy: 0.5703\n",
      "Epoch 149/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.9859 - categorical_accuracy: 0.5859\n",
      "Epoch 150/1000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.9850 - categorical_accuracy: 0.6055\n",
      "Epoch 151/1000\n",
      "8/8 [==============================] - 1s 111ms/step - loss: 0.8796 - categorical_accuracy: 0.6133\n",
      "Epoch 152/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.7578 - categorical_accuracy: 0.6797\n",
      "Epoch 153/1000\n",
      "8/8 [==============================] - 1s 137ms/step - loss: 0.6578 - categorical_accuracy: 0.7617\n",
      "Epoch 154/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.7433 - categorical_accuracy: 0.7695\n",
      "Epoch 155/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.7211 - categorical_accuracy: 0.7109\n",
      "Epoch 156/1000\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.6601 - categorical_accuracy: 0.7695\n",
      "Epoch 157/1000\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.6026 - categorical_accuracy: 0.8281\n",
      "Epoch 158/1000\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.5474 - categorical_accuracy: 0.8281\n",
      "Epoch 159/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.4960 - categorical_accuracy: 0.8281\n",
      "Epoch 160/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.5218 - categorical_accuracy: 0.8125\n",
      "Epoch 161/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.6267 - categorical_accuracy: 0.7227\n",
      "Epoch 162/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.5702 - categorical_accuracy: 0.7852\n",
      "Epoch 163/1000\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.5204 - categorical_accuracy: 0.7852\n",
      "Epoch 164/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.4345 - categorical_accuracy: 0.8047\n",
      "Epoch 165/1000\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.4113 - categorical_accuracy: 0.8477\n",
      "Epoch 166/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.3921 - categorical_accuracy: 0.8555\n",
      "Epoch 167/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3807 - categorical_accuracy: 0.8555\n",
      "Epoch 168/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.3496 - categorical_accuracy: 0.8477\n",
      "Epoch 169/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 0.3164 - categorical_accuracy: 0.9062\n",
      "Epoch 170/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3152 - categorical_accuracy: 0.8672\n",
      "Epoch 171/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.4308 - categorical_accuracy: 0.8477\n",
      "Epoch 172/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.4447 - categorical_accuracy: 0.8320\n",
      "Epoch 173/1000\n",
      "8/8 [==============================] - 1s 114ms/step - loss: 0.3538 - categorical_accuracy: 0.8555\n",
      "Epoch 174/1000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.3338 - categorical_accuracy: 0.8672\n",
      "Epoch 175/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.3403 - categorical_accuracy: 0.8789\n",
      "Epoch 176/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.2747 - categorical_accuracy: 0.9180\n",
      "Epoch 177/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.5556 - categorical_accuracy: 0.8047\n",
      "Epoch 178/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.7330 - categorical_accuracy: 0.7305\n",
      "Epoch 179/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.4244 - categorical_accuracy: 0.8477\n",
      "Epoch 180/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.5972 - categorical_accuracy: 0.7930\n",
      "Epoch 181/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.6083 - categorical_accuracy: 0.7305\n",
      "Epoch 182/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.5043 - categorical_accuracy: 0.7852\n",
      "Epoch 183/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.4440 - categorical_accuracy: 0.8125\n",
      "Epoch 184/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.3986 - categorical_accuracy: 0.8594\n",
      "Epoch 185/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.3815 - categorical_accuracy: 0.8633\n",
      "Epoch 186/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.3631 - categorical_accuracy: 0.8477\n",
      "Epoch 187/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.3860 - categorical_accuracy: 0.8242\n",
      "Epoch 188/1000\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.3623 - categorical_accuracy: 0.8477\n",
      "Epoch 189/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.3264 - categorical_accuracy: 0.8594\n",
      "Epoch 190/1000\n",
      "8/8 [==============================] - 1s 116ms/step - loss: 1.3506 - categorical_accuracy: 0.6953\n",
      "Epoch 191/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 1.3891 - categorical_accuracy: 0.4609\n",
      "Epoch 192/1000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.9227 - categorical_accuracy: 0.6211\n",
      "Epoch 193/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.8007 - categorical_accuracy: 0.7188\n",
      "Epoch 194/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.6971 - categorical_accuracy: 0.7539\n",
      "Epoch 195/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.6159 - categorical_accuracy: 0.7891\n",
      "Epoch 196/1000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.5439 - categorical_accuracy: 0.7773\n",
      "Epoch 197/1000\n",
      "8/8 [==============================] - 1s 149ms/step - loss: 0.4918 - categorical_accuracy: 0.8164\n",
      "Epoch 198/1000\n",
      "8/8 [==============================] - 1s 167ms/step - loss: 0.4520 - categorical_accuracy: 0.8281\n",
      "Epoch 199/1000\n",
      "8/8 [==============================] - 1s 168ms/step - loss: 0.4362 - categorical_accuracy: 0.8594\n",
      "Epoch 200/1000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.5071 - categorical_accuracy: 0.8477\n",
      "Epoch 201/1000\n",
      "8/8 [==============================] - 1s 135ms/step - loss: 0.4181 - categorical_accuracy: 0.8633\n",
      "Epoch 202/1000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.3986 - categorical_accuracy: 0.8633\n",
      "Epoch 203/1000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.4053 - categorical_accuracy: 0.8555\n",
      "Epoch 204/1000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.3536 - categorical_accuracy: 0.8594\n",
      "Epoch 205/1000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.3364 - categorical_accuracy: 0.8984\n",
      "Epoch 206/1000\n",
      "8/8 [==============================] - 1s 140ms/step - loss: 0.3245 - categorical_accuracy: 0.8789\n",
      "Epoch 207/1000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.2958 - categorical_accuracy: 0.8906\n",
      "Epoch 208/1000\n",
      "8/8 [==============================] - 1s 143ms/step - loss: 0.2484 - categorical_accuracy: 0.9180\n",
      "Epoch 209/1000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.2810 - categorical_accuracy: 0.8906\n",
      "Epoch 210/1000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.2869 - categorical_accuracy: 0.8906\n",
      "Epoch 211/1000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.2885 - categorical_accuracy: 0.8711\n",
      "Epoch 212/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.2669 - categorical_accuracy: 0.9102\n",
      "Epoch 213/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2336 - categorical_accuracy: 0.9219\n",
      "Epoch 214/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.1954 - categorical_accuracy: 0.9258\n",
      "Epoch 215/1000\n",
      "8/8 [==============================] - 1s 117ms/step - loss: 0.3918 - categorical_accuracy: 0.8906\n",
      "Epoch 216/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.5856 - categorical_accuracy: 0.7852\n",
      "Epoch 217/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.4468 - categorical_accuracy: 0.8320\n",
      "Epoch 218/1000\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.4053 - categorical_accuracy: 0.8555\n",
      "Epoch 219/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.3196 - categorical_accuracy: 0.9023\n",
      "Epoch 220/1000\n",
      "8/8 [==============================] - 1s 144ms/step - loss: 0.2898 - categorical_accuracy: 0.9102\n",
      "Epoch 221/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2510 - categorical_accuracy: 0.9180\n",
      "Epoch 222/1000\n",
      "8/8 [==============================] - 1s 113ms/step - loss: 0.2930 - categorical_accuracy: 0.8906\n",
      "Epoch 223/1000\n",
      "8/8 [==============================] - 1s 136ms/step - loss: 0.2682 - categorical_accuracy: 0.9023\n",
      "Epoch 224/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.2473 - categorical_accuracy: 0.9102\n",
      "Epoch 225/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.3026 - categorical_accuracy: 0.8945\n",
      "Epoch 226/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2774 - categorical_accuracy: 0.8945\n",
      "Epoch 227/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.2331 - categorical_accuracy: 0.9062\n",
      "Epoch 228/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.2514 - categorical_accuracy: 0.9102\n",
      "Epoch 229/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.2279 - categorical_accuracy: 0.9180\n",
      "Epoch 230/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.1908 - categorical_accuracy: 0.9375\n",
      "Epoch 231/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.2696 - categorical_accuracy: 0.8984\n",
      "Epoch 232/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2056 - categorical_accuracy: 0.9258\n",
      "Epoch 233/1000\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.1759 - categorical_accuracy: 0.9414\n",
      "Epoch 234/1000\n",
      "8/8 [==============================] - 1s 123ms/step - loss: 0.1805 - categorical_accuracy: 0.9297\n",
      "Epoch 235/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.1571 - categorical_accuracy: 0.9531\n",
      "Epoch 236/1000\n",
      "8/8 [==============================] - 1s 112ms/step - loss: 0.4978 - categorical_accuracy: 0.7812\n",
      "Epoch 237/1000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.3718 - categorical_accuracy: 0.8555\n",
      "Epoch 238/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.2598 - categorical_accuracy: 0.8984\n",
      "Epoch 239/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2193 - categorical_accuracy: 0.9453\n",
      "Epoch 240/1000\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.2038 - categorical_accuracy: 0.9336\n",
      "Epoch 241/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.1818 - categorical_accuracy: 0.9570\n",
      "Epoch 242/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1699 - categorical_accuracy: 0.9531\n",
      "Epoch 243/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.1521 - categorical_accuracy: 0.9492\n",
      "Epoch 244/1000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.1557 - categorical_accuracy: 0.9414\n",
      "Epoch 245/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.1474 - categorical_accuracy: 0.9570\n",
      "Epoch 246/1000\n",
      "8/8 [==============================] - 1s 121ms/step - loss: 0.1312 - categorical_accuracy: 0.9609\n",
      "Epoch 247/1000\n",
      "8/8 [==============================] - 1s 139ms/step - loss: 0.2033 - categorical_accuracy: 0.9258\n",
      "Epoch 248/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.1849 - categorical_accuracy: 0.9375\n",
      "Epoch 249/1000\n",
      "8/8 [==============================] - 1s 119ms/step - loss: 0.1729 - categorical_accuracy: 0.9375\n",
      "Epoch 250/1000\n",
      "8/8 [==============================] - 1s 133ms/step - loss: 0.4109 - categorical_accuracy: 0.8594\n",
      "Epoch 251/1000\n",
      "8/8 [==============================] - 1s 142ms/step - loss: 0.2837 - categorical_accuracy: 0.8828\n",
      "Epoch 252/1000\n",
      "8/8 [==============================] - 1s 127ms/step - loss: 0.2371 - categorical_accuracy: 0.8945\n",
      "Epoch 253/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.2422 - categorical_accuracy: 0.8906\n",
      "Epoch 254/1000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.1599 - categorical_accuracy: 0.9453\n",
      "Epoch 255/1000\n",
      "8/8 [==============================] - 1s 126ms/step - loss: 0.1397 - categorical_accuracy: 0.9570\n",
      "Epoch 256/1000\n",
      "8/8 [==============================] - 1s 118ms/step - loss: 0.1447 - categorical_accuracy: 0.9570\n",
      "Epoch 257/1000\n",
      "8/8 [==============================] - 1s 134ms/step - loss: 0.1586 - categorical_accuracy: 0.9414\n",
      "Epoch 258/1000\n",
      "8/8 [==============================] - 1s 132ms/step - loss: 0.1209 - categorical_accuracy: 0.9492\n",
      "Epoch 259/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.1195 - categorical_accuracy: 0.9609\n",
      "Epoch 260/1000\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.1223 - categorical_accuracy: 0.9648\n",
      "Epoch 261/1000\n",
      "8/8 [==============================] - 1s 131ms/step - loss: 0.0898 - categorical_accuracy: 0.9648\n",
      "Epoch 262/1000\n",
      "8/8 [==============================] - 1s 122ms/step - loss: 0.1073 - categorical_accuracy: 0.9688\n",
      "Epoch 263/1000\n",
      "8/8 [==============================] - 1s 129ms/step - loss: 0.0987 - categorical_accuracy: 0.9727\n",
      "Epoch 264/1000\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0958 - categorical_accuracy: 0.9648\n",
      "Epoch 265/1000\n",
      "8/8 [==============================] - 1s 128ms/step - loss: 0.1164 - categorical_accuracy: 0.9609\n",
      "Epoch 266/1000\n",
      "8/8 [==============================] - 1s 147ms/step - loss: 0.1883 - categorical_accuracy: 0.9453\n",
      "Epoch 267/1000\n",
      "8/8 [==============================] - 1s 115ms/step - loss: 0.1228 - categorical_accuracy: 0.9688\n",
      "Epoch 268/1000\n",
      "8/8 [==============================] - 1s 145ms/step - loss: 0.1301 - categorical_accuracy: 0.9609\n",
      "Epoch 269/1000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.0952 - categorical_accuracy: 0.9766\n",
      "Epoch 270/1000\n",
      "8/8 [==============================] - 1s 120ms/step - loss: 0.0619 - categorical_accuracy: 0.9805\n",
      "Epoch 271/1000\n",
      "8/8 [==============================] - 1s 130ms/step - loss: 0.0557 - categorical_accuracy: 0.9883\n",
      "Epoch 272/1000\n",
      "8/8 [==============================] - 1s 141ms/step - loss: 0.0451 - categorical_accuracy: 0.9805\n",
      "Epoch 273/1000\n",
      "8/8 [==============================] - 1s 125ms/step - loss: 0.0301 - categorical_accuracy: 0.9883\n",
      "Epoch 274/1000\n",
      "8/8 [==============================] - ETA: 0s - loss: 0.0252 - categorical_accuracy: 0.9922\n",
      "Epoch 274: early stopping threshold of 0.99 reached. Stopping training.\n",
      "8/8 [==============================] - 1s 124ms/step - loss: 0.0252 - categorical_accuracy: 0.9922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23000179a50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "# from tensorflow.keras.callbacks import TensorBoard, Callback\n",
    "# import os\n",
    "\n",
    "# class EarlyStoppingByAccuracy(Callback):\n",
    "#     def __init__(self, monitor='categorical_accuracy', value=0.99, verbose=1):\n",
    "#         super(Callback, self).__init__()\n",
    "#         self.monitor = monitor\n",
    "#         self.value = value\n",
    "#         self.verbose = verbose\n",
    "\n",
    "#     def on_epoch_end(self, epoch, logs={}):\n",
    "#         current = logs.get(self.monitor)\n",
    "#         if current is None:\n",
    "#             raise ValueError(f\"Monitor '{self.monitor}' is not available in logs. Available keys are: {', '.join(logs.keys())}\")\n",
    "        \n",
    "#         if current >= self.value:\n",
    "#             if self.verbose > 0:\n",
    "#                 print(f\"\\nEpoch {epoch + 1}: early stopping threshold of {self.value} reached. Stopping training.\")\n",
    "#             self.model.stop_training = True\n",
    "\n",
    "# log_dir = os.path.join(\"logs\")\n",
    "# tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(LSTM(128, activation='relu', return_sequences=True, input_shape=(70, 111))) \n",
    "# model.add(LSTM(128, activation='relu', return_sequences=True)) \n",
    "# model.add(LSTM(64, activation='relu', return_sequences=False)) \n",
    "# model.add(Dense(64, activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(8, activation='softmax'))\n",
    "\n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "# # Define the early stopping callback\n",
    "# early_stopping_callback = EarlyStoppingByAccuracy(monitor='categorical_accuracy', value=0.99)\n",
    "\n",
    "# model.fit(X_train, y_train, epochs=1000, callbacks=[tb_callback, early_stopping_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b67532c-9a06-4515-94d6-6ba5a141877f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "accuracy:\n",
      "0.984375\n",
      "confusion matrix:\n",
      "[[ 7  0  0  0  0  0  0  0]\n",
      " [ 0  6  0  0  0  0  0  1]\n",
      " [ 0  0  7  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0]\n",
      " [ 0  0  0  0  0  7  0  0]\n",
      " [ 0  0  0  0  0  0  8  0]\n",
      " [ 0  0  0  0  0  0  0 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Make predictions on the test set\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test if one-hot encoded\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "#accuracy and loss\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('accuracy:')\n",
    "print(accuracy)\n",
    "# Generate the confusion matrix\n",
    "print('confusion matrix:')\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfcebf41-e5ea-4b7d-a00c-b8bdc4a233fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 70, 128)           122880    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 70, 128)           131584    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 264       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 310376 (1.18 MB)\n",
      "Trainable params: 310376 (1.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f786886f-3975-48c0-a07d-a3e243ab4826",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "model.save('my_model3.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af4bf9c8-735c-4eee-b9f0-3c10110b9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002347ED48820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 393ms/step\n",
      "Time taken to make predictions: 0.4266395568847656 seconds\n",
      "2/2 [==============================] - 0s 39ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       0.92      1.00      0.96        11\n",
      "           3       1.00      1.00      1.00        10\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       1.00      1.00      1.00         5\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.98        64\n",
      "   macro avg       0.99      0.99      0.99        64\n",
      "weighted avg       0.99      0.98      0.98        64\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 8  0  1  0  0  0  0  0]\n",
      " [ 0 11  0  0  0  0  0  0]\n",
      " [ 0  0 11  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  6  0  0  0]\n",
      " [ 0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  6  0]\n",
      " [ 0  0  0  0  0  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = load_model('my_model2.keras')\n",
    "\n",
    "data = pd.read_csv('keypoints\\\\come\\\\1.csv')\n",
    "\n",
    "# Extract only the values as a numpy array\n",
    "keypoints = data.values\n",
    "keypoints = np.expand_dims(keypoints, axis=0)  # Expand dimensions to match the model input shape (1, 70, 111)\n",
    "# Measure prediction time\n",
    "start_time = time.time()\n",
    "predictions = model.predict(keypoints)\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "\n",
    "print(f\"Time taken to make predictions: {elapsed_time} seconds\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test if one-hot encoded\n",
    "if y_test.ndim > 1:\n",
    "    y_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print confusion matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
